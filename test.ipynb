{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6756fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanzeel.shaikh/Library/Caches/pypoetry/virtualenvs/gnn-hgt-4314cFo1-py3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from typing import List, Dict, Any\n",
    "import os\n",
    "\n",
    "# Set your Hugging Face token here\n",
    "# Option 1: Set it as an environment variable\n",
    "os.environ['HF_TOKEN'] = ''\n",
    "\n",
    "# Option 2: Use huggingface_hub login (recommended)\n",
    "# from huggingface_hub import login\n",
    "# login(token='your_token_here')\n",
    "\n",
    "def load_musique_from_hf() -> List[Dict[str, Any]]:\n",
    "    ds = load_dataset(\"dgslibisey/MuSiQue\")\n",
    "    \n",
    "    episodes = []\n",
    "    for item in ds['train']:  # Adjust split as needed ('train', 'validation', 'test')\n",
    "        chunks = []\n",
    "        for p in item['paragraphs']:\n",
    "            chunks.append({\n",
    "                'text': f\"{p['title']}\\n{p['paragraph_text']}\",\n",
    "                'metadata': {\n",
    "                    'title': p['title'],\n",
    "                    'idx': p['idx'],\n",
    "                    'is_supporting': p.get('is_supporting', False)\n",
    "                }\n",
    "            })\n",
    "        episodes.append({\n",
    "            'id': item['id'],\n",
    "            'question': item['question'],\n",
    "            'chunks': chunks\n",
    "        })\n",
    "    return episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "babf8e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "        \"musique\": {\n",
    "            \"path\": \"Projects/QSGNN/reproduce/dataset/musique_all.json\",\n",
    "            \"loader\": load_musique_from_hf\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1569422e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 19938/19938 [00:00<00:00, 92898.72 examples/s]\n",
      "Generating validation split: 100%|██████████| 2417/2417 [00:00<00:00, 106791.74 examples/s]\n"
     ]
    }
   ],
   "source": [
    "processed_episodes =[]\n",
    "for name, config in datasets.items():\n",
    "        #data_path = config['path']\n",
    "        #if not os.path.exists(data_path):\n",
    "        #    print(f\"Skipping {name}, file not found: {data_path}\")\n",
    "        #    continue\n",
    "            \n",
    "        #print(f\"Processing {name} from {data_path}...\")\n",
    "        episodes = config['loader']()\n",
    "        \n",
    "        # Limit processing for large datasets if needed\n",
    "        # processed_episodes = episodes[:100] \n",
    "        processed_episodes = episodes[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8753c551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '2hop__482757_12019',\n",
       "  'question': 'When was the institute that owned The Collegian founded?',\n",
       "  'chunks': [{'text': 'Pakistan Super League\\nPakistan Super League (Urdu: پاکستان سپر لیگ \\u202c \\u200e; PSL) is a Twenty20 cricket league, founded in Lahore on 9 September 2015 with five teams and now comprises six teams. Instead of operating as an association of independently owned teams, the league is a single entity in which each franchise is owned and controlled by investors.',\n",
       "    'metadata': {'title': 'Pakistan Super League',\n",
       "     'idx': 0,\n",
       "     'is_supporting': False}},\n",
       "   {'text': 'Serena Wilson\\nSerena Wilson (August 8, 1933 – June 17, 2007), often known just as \"Serena\", was a well-known dancer, choreographer, and teacher who helped popularize belly dance in the United States. Serena\\'s work also helped legitimize the dance form and helped it to be perceived as more than burlesque or stripping. Serena danced in clubs in her younger years, opened her own studio, hosted her own television show, founded her own dance troupe, and was the author of several books about belly dance.',\n",
       "    'metadata': {'title': 'Serena Wilson', 'idx': 1, 'is_supporting': False}},\n",
       "   {'text': 'Longman\\nLongman, also known as Pearson Longman, is a publishing company founded in London, England, in 1724 and is owned by Pearson PLC.',\n",
       "    'metadata': {'title': 'Longman', 'idx': 2, 'is_supporting': False}},\n",
       "   {'text': 'Bankhaus Lampe\\nBankhaus Lampe is a private bank in Germany, founded in 1852 and headquartered in Bielefeld. It is wholly owned by the Oetker Group. The bank owns 50% of Universal Investment.',\n",
       "    'metadata': {'title': 'Bankhaus Lampe', 'idx': 3, 'is_supporting': False}},\n",
       "   {'text': 'Publix\\nPublix Super Markets, Inc., commonly known as Publix, is an employee - owned, American supermarket chain headquartered in Lakeland, Florida. Founded in 1930 by George W. Jenkins, Publix is a private corporation that is wholly owned by present and past employees. It is considered the largest employee - owned company in the world. Publix operates throughout the Southeastern United States, with locations in Florida (785), Georgia (186), Alabama (68), South Carolina (58), Tennessee (42), North Carolina (35), and Virginia (8).',\n",
       "    'metadata': {'title': 'Publix', 'idx': 4, 'is_supporting': False}},\n",
       "   {'text': 'The Collegian (Houston Baptist University)\\nThe Collegian is the bi-weekly official student publication of Houston Baptist University in Houston, Texas. It was founded in 1963 as a newsletter, and adopted the newspaper format in 1990.',\n",
       "    'metadata': {'title': 'The Collegian (Houston Baptist University)',\n",
       "     'idx': 5,\n",
       "     'is_supporting': True}},\n",
       "   {'text': \"The Collegian (Hillsdale College)\\nThe Collegian is the oldest college newspaper in Michigan. The paper's history traces back to 1878, when the Hillsdale Herald was first published. The administration started The Collegian in 1893 as a rival paper to the Herald.\",\n",
       "    'metadata': {'title': 'The Collegian (Hillsdale College)',\n",
       "     'idx': 6,\n",
       "     'is_supporting': False}},\n",
       "   {'text': 'List of Old Scotch Collegians\\nThis is a list of Old Scotch Collegians, who are notable former students of Scotch College in Melbourne, Victoria, Australia.',\n",
       "    'metadata': {'title': 'List of Old Scotch Collegians',\n",
       "     'idx': 7,\n",
       "     'is_supporting': False}},\n",
       "   {'text': 'Renaissance Broadcasting\\nRenaissance Broadcasting, founded in 1982 by Michael Finkelstein, was a company that owned several UHF television stations, it was sold to Tribune Broadcasting in 1997. The company was headquartered in Greenwich, Connecticut.',\n",
       "    'metadata': {'title': 'Renaissance Broadcasting',\n",
       "     'idx': 8,\n",
       "     'is_supporting': False}},\n",
       "   {'text': \"Houston\\nSeveral private institutions of higher learning—ranging from liberal arts colleges, such as The University of St. Thomas, Houston's only Catholic university, to Rice University, the nationally recognized research university—are located within the city. Rice, with a total enrollment of slightly more than 6,000 students, has a number of distinguished graduate programs and research institutes, such as the James A. Baker Institute for Public Policy. Houston Baptist University, affiliated with the Baptist General Convention of Texas, offers bachelor's and graduate degrees. It was founded in 1960 and is located in the Sharpstown area in Southwest Houston.\",\n",
       "    'metadata': {'title': 'Houston', 'idx': 9, 'is_supporting': True}},\n",
       "   {'text': 'France-Guyane\\nFrance-Guyane is a daily, French-language newspaper headquartered in Cayenne, French Guiana. Founded in 1973, the newspaper is owned by \"French-Antilles\", which is controlled by the Groupe Hersant Média group.',\n",
       "    'metadata': {'title': 'France-Guyane', 'idx': 10, 'is_supporting': False}},\n",
       "   {'text': 'Bayou City Broadcasting\\nBayou City Broadcasting, LLC is a broadcasting company founded in December 2007 and owned by DuJuan McCoy. The company is based in The Woodlands, Texas.',\n",
       "    'metadata': {'title': 'Bayou City Broadcasting',\n",
       "     'idx': 11,\n",
       "     'is_supporting': False}},\n",
       "   {'text': 'GKS Górnik 1979 Łęczna\\nGKS Górnik 1979 Łęczna was a short-lived fan-owned phoenix club founded in 2011 by Górnik Łęczna fans who were unhappy with the name change to GKS Bogdanka. The club eventually changed its name back in 2013 but the fan owned counterpart has continued to operate in amateur football leagues until 2014.',\n",
       "    'metadata': {'title': 'GKS Górnik 1979 Łęczna',\n",
       "     'idx': 12,\n",
       "     'is_supporting': False}},\n",
       "   {'text': 'Broadway Federal Bank\\nThe Broadway Federal Bank is a community bank founded in 1946 and based in Los Angeles. As of 2011, it owned and operated three traditional branches and one loan production office.',\n",
       "    'metadata': {'title': 'Broadway Federal Bank',\n",
       "     'idx': 13,\n",
       "     'is_supporting': False}},\n",
       "   {'text': 'Gubernija\\nGubernija is a brewery in Lithuania. It is one of the oldest businesses in the world, having been founded in 1665. Gubernija is listed on the NASDAQ OMX Vilnius stock exchange. Unlike other Lithuanian breweries, Gubernija has its own pubs.',\n",
       "    'metadata': {'title': 'Gubernija', 'idx': 14, 'is_supporting': False}},\n",
       "   {'text': 'Nordic Paper\\nNordic Paper AS is a Norwegian industrial company, operating in Norway and Sweden. It was founded in 2001 when \"Peterson Scanproof\", a branch of M. Peterson & Søn which consisted of production units in Greåker (formerly owned by Greaker Industrier) and Säffle, was merged with a paper factory in Geithus, owned by Norske Skog Union.',\n",
       "    'metadata': {'title': 'Nordic Paper', 'idx': 15, 'is_supporting': False}},\n",
       "   {'text': 'Logica\\nLogica was a multinational IT and management consultancy company headquartered in Reading, United Kingdom. Founded in 1969, the company became a wholly owned subsidiary of CGI Group in 2012.',\n",
       "    'metadata': {'title': 'Logica', 'idx': 16, 'is_supporting': False}},\n",
       "   {'text': 'Skipton Business Finance\\nSkipton Business Finance is a UK factoring and Invoice discounting company, founded and based in Skipton, North Yorkshire. It is a wholly owned subsidiary of Skipton Building Society.',\n",
       "    'metadata': {'title': 'Skipton Business Finance',\n",
       "     'idx': 17,\n",
       "     'is_supporting': False}},\n",
       "   {'text': 'Brett Kearney\\nBrett Kearney (born 29 September 1983 in Sydney, New South Wales), also known by the nickname of \"BK\", is an Australian professional rugby league footballer formerly with the Bradford Bulls in the Super League, now currently playing for the Collegians in the Illawarra Rugby League competition. A utility back, he has represented Country Origin and previously played for the South Sydney Rabbitohs and Cronulla.',\n",
       "    'metadata': {'title': 'Brett Kearney', 'idx': 18, 'is_supporting': False}},\n",
       "   {'text': 'Grand Duchy of Baden State Railway\\nThe Grand Duchy of Baden was an independent state in what is now southwestern Germany until the creation of the German Empire in 1871. It had its own state-owned railway company, the Grand Duchy of Baden State Railways (\"Großherzoglich Badische Staatseisenbahnen or G.Bad.St.E.\"), which was founded in 1840. At the time when it was integrated into the Deutsche Reichsbahn in 1920, its network had an overall length of about .',\n",
       "    'metadata': {'title': 'Grand Duchy of Baden State Railway',\n",
       "     'idx': 19,\n",
       "     'is_supporting': False}}]}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_episodes[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "29b2a7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes Created: 6 Entities, 2 Sentences, 1 Passage\n",
      "\n",
      "--- Graph Edge Summary ---\n",
      "Edge ('entity', 're', 'entity'): 2 connections\n",
      "Edge ('sentence', 'in', 'passage'): 2 connections\n",
      "Edge ('passage', 'hv', 'sentence'): 2 connections\n",
      "Edge ('entity', 'in', 'passage'): 6 connections\n",
      "Edge ('passage', 'hv', 'entity'): 6 connections\n",
      "Edge ('sentence', 're', 'sentence'): 2 connections\n",
      "\n",
      "Final HeteroData Object:\n",
      "HeteroData(\n",
      "  entity={ x=[6, 128] },\n",
      "  sentence={ x=[2, 128] },\n",
      "  passage={ x=[1, 128] },\n",
      "  (entity, re, entity)={ edge_index=[2, 2] },\n",
      "  (sentence, in, passage)={ edge_index=[2, 2] },\n",
      "  (passage, hv, sentence)={ edge_index=[2, 2] },\n",
      "  (entity, in, passage)={ edge_index=[2, 6] },\n",
      "  (passage, hv, entity)={ edge_index=[2, 6] },\n",
      "  (sentence, re, sentence)={ edge_index=[2, 2] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch_geometric.data import HeteroData\n",
    "import hashlib\n",
    "\n",
    "# --- SIMULATED DATA (From MuSiQue Example) ---\n",
    "# Question: \"When was the institute that owned The Collegian founded?\"\n",
    "passage_content = (\n",
    "    \"The Collegian (Houston Baptist University)\\n\"\n",
    "    \"The Collegian is the bi-weekly official student publication of Houston Baptist University in Houston, Texas. \"\n",
    "    \"It was founded in 1963 as a newsletter.\"\n",
    ")\n",
    "\n",
    "# 1. Sentences extracted from passage\n",
    "sentences = [\n",
    "    \"The Collegian is the bi-weekly official student publication of Houston Baptist University in Houston, Texas.\",\n",
    "    \"It was founded in 1963 as a newsletter.\"\n",
    "]\n",
    "\n",
    "# 2. Entities extracted from sentences\n",
    "sentence_entities = [\n",
    "    [\"The Collegian\", \"Houston Baptist University\", \"Houston\", \"Texas\"], # From Sentence 0\n",
    "    [\"1963\", \"newsletter\"]                                             # From Sentence 1\n",
    "]\n",
    "\n",
    "# 3. Triples (OpenIE results) representing Entity-Entity relations\n",
    "# Format: (Subject, Relation, Object)\n",
    "triples = [\n",
    "    (\"The Collegian\", \"is publication of\", \"Houston Baptist University\"),\n",
    "    (\"The Collegian\", \"founded in\", \"1963\")\n",
    "]\n",
    "\n",
    "# --- CONSTRUCTION LOGIC ---\n",
    "\n",
    "def compute_id(text, prefix=\"\"):\n",
    "    \"\"\"Helper to create consistent IDs for nodes.\"\"\"\n",
    "    return prefix + hashlib.mdsafe(text.encode()).hexdigest()[:10]\n",
    "\n",
    "def test_construction():\n",
    "    data = HeteroData()\n",
    "    \n",
    "    # In the real code, these are real embeddings (e.g., from NV-Embed-v2)\n",
    "    # Here we use dummy vectors of size 128\n",
    "    EMB_DIM = 128\n",
    "    \n",
    "    # Unique lists for nodes\n",
    "    all_entities = sorted(list(set([t[0] for t in triples] + [t[2] for t in triples] + [ent for sublist in sentence_entities for ent in sublist])))\n",
    "    entity_to_idx = {ent: i for i, ent in enumerate(all_entities)}\n",
    "    \n",
    "    # 1. Define Nodes (Level 1: Entity, Level 2: Sentence, Level 3: Passage)\n",
    "    data['entity'].x = torch.randn(len(all_entities), EMB_DIM)\n",
    "    data['sentence'].x = torch.randn(len(sentences), EMB_DIM)\n",
    "    data['passage'].x = torch.randn(1, EMB_DIM)\n",
    "    \n",
    "    print(f\"Nodes Created: {len(all_entities)} Entities, {len(sentences)} Sentences, 1 Passage\")\n",
    "\n",
    "    # 2. Define Edges\n",
    "    \n",
    "    # A. Entity -> Entity (from Triples)\n",
    "    e2e_edges = []\n",
    "    entity_to_entity_attrs =[]\n",
    "    for sub, rel, obj in triples: # no bidirectional edges where edges have attributes\n",
    "        e2e_edges.append([entity_to_idx[sub], entity_to_idx[obj]])\n",
    "        entity_to_entity_attrs.append(obj)\n",
    "        #e2e_edges.append([entity_to_idx[obj], entity_to_idx[sub]]) \n",
    "    data['entity', 're', 'entity'].edge_index = torch.tensor(e2e_edges).t().contiguous()\n",
    "\n",
    "    # B. Sentence -> Passage (Hierarchical)\n",
    "    s2p_edges = [[i, 0] for i in range(len(sentences))]\n",
    "    data['sentence', 'in', 'passage'].edge_index = torch.tensor(s2p_edges).t().contiguous()\n",
    "    data['passage', 'hv', 'sentence'].edge_index = torch.tensor([[0, i] for i in range(len(sentences))]).t().contiguous()\n",
    "\n",
    "    # C. Entity -> Sentence (Mapping entities to where they appear)\n",
    "    e2s_edges = []\n",
    "    for s_idx, ents in enumerate(sentence_entities):\n",
    "        for ent in ents:\n",
    "            e2s_edges.append([entity_to_idx[ent], s_idx])\n",
    "    data['entity', 'in', 'passage'].edge_index = torch.tensor(e2s_edges).t().contiguous()\n",
    "    data['passage', 'hv', 'entity'].edge_index = torch.tensor([[v, k] for k, v in e2s_edges]).t().contiguous()\n",
    "\n",
    "    # D. Sentence -> Sentence (Intra-level context)\n",
    "    # Fully connected within the passage\n",
    "    s2s_edges = []\n",
    "    for i in range(len(sentences)):\n",
    "        for j in range(len(sentences)):\n",
    "            if i != j: s2s_edges.append([i, j])\n",
    "    data['sentence', 're', 'sentence'].edge_index = torch.tensor(s2s_edges).t().contiguous()\n",
    "\n",
    "    print(\"\\n--- Graph Edge Summary ---\")\n",
    "    for edge_type in data.edge_types:\n",
    "        print(f\"Edge {edge_type}: {data[edge_type].edge_index.shape[1]} connections\")\n",
    "\n",
    "    return data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    graph = test_construction()\n",
    "    print(\"\\nFinal HeteroData Object:\")\n",
    "    print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d75fd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_entities = sorted(list(set([t[0] for t in triples] + [t[2] for t in triples] + [ent for sublist in sentence_entities for ent in sublist])))\n",
    "entity_to_idx = {ent: i for i, ent in enumerate(all_entities)}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2796dfbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1963': 0,\n",
       " 'Houston': 1,\n",
       " 'Houston Baptist University': 2,\n",
       " 'Texas': 3,\n",
       " 'The Collegian': 4,\n",
       " 'newsletter': 5}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7619a4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "e2e_edges_1 = []\n",
    "for sub, rel, obj in triples:\n",
    "    e2e_edges_1.append([entity_to_idx[sub], entity_to_idx[obj]])\n",
    "    e2e_edges_1.append([entity_to_idx[obj], entity_to_idx[sub]]) # Bidirectional\n",
    "\n",
    "#torch.tensor(e2e_edges_1).t().contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96c08b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4, 2], [2, 4], [4, 0], [0, 4]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e2e_edges_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d276e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 2, 4, 0],\n",
       "        [2, 4, 0, 4]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(e2e_edges_1).t().contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b76e3a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(e2e_edges_1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18061206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(e2e_edges_1).t()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e5e17ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MockEmbeddingModel:\n",
    "    def __init__(self, dim=128):\n",
    "        self.dim = dim\n",
    "\n",
    "    #check what happens here\n",
    "    def batch_encode(self, texts: List[str]) -> List[np.ndarray]:\n",
    "        print(f\"  [AI Model] Encoding {len(texts)} new strings...\")\n",
    "        # Simulating vector generation\n",
    "        return [np.random.rand(self.dim).astype(np.float32) for _ in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29e45e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. STRIPPED DOWN EMBEDDING STORE ---\n",
    "# Simplified version of src/qsgnn_rag/embedding_store.py\n",
    "class SimpleEmbeddingStore:\n",
    "    def __init__(self, model, namespace: str):\n",
    "        self.model = model\n",
    "        self.namespace = namespace\n",
    "        self.cache = {} # hash_id -> {'content': str, 'embedding': np.array}\n",
    "        self.hash_id_to_idx = {} # hash_id -> integer index (for GNN)\n",
    "\n",
    "    def _compute_hash(self, text: str) -> str:\n",
    "        \"\"\"Creates a unique ID for every string.\"\"\"\n",
    "        return self.namespace + \"-\" + hashlib.md5(text.encode()).hexdigest()[:12]\n",
    "\n",
    "    def insert(self, texts: List[str]):\n",
    "        \"\"\"Inserts strings, only encoding those that aren't already cached.\"\"\"\n",
    "        unique_texts = list(set(texts))\n",
    "        \n",
    "        # Step 1: Identify which strings are actually new\n",
    "        to_encode = []\n",
    "        for text in unique_texts:\n",
    "            h_id = self._compute_hash(text)\n",
    "            if h_id not in self.cache:\n",
    "                to_encode.append(text)\n",
    "        \n",
    "        # Step 2: Only call the expensive AI model for NEW strings\n",
    "        if to_encode:\n",
    "            new_vectors = self.model.batch_encode(to_encode)\n",
    "            for text, vec in zip(to_encode, new_vectors):\n",
    "                h_id = self._compute_hash(text)\n",
    "                self.cache[h_id] = {'content': text, 'embedding': vec}\n",
    "\n",
    "        # Step 3: Refresh the index mapping (needed for Graph construction)\n",
    "        all_ids = sorted(list(self.cache.keys()))\n",
    "        self.hash_id_to_idx = {h_id: i for i, h_id in enumerate(all_ids)}\n",
    "\n",
    "    def get_all_vectors(self) -> np.ndarray:\n",
    "        \"\"\"Returns a matrix of all embeddings in indexed order.\"\"\"\n",
    "        sorted_ids = sorted(list(self.cache.keys()))\n",
    "        return np.array([self.cache[h_id]['embedding'] for h_id in sorted_ids])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bc6c13",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66a0e863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: First indexing...\n",
      "  [AI Model] Encoding 3 new strings...\n",
      "\n",
      "Step 2: Second indexing (with duplicates)...\n",
      "  [AI Model] Encoding 2 new strings...\n",
      "\n",
      "Final Store Size: 5 unique entities\n",
      "Matrix Shape for GNN: (5, 8)\n",
      "The entity 'Houston' is mapped to GNN Node Index: 3\n"
     ]
    }
   ],
   "source": [
    "# --- 3. DEMONSTRATION ---\n",
    "if __name__ == \"__main__\":\n",
    "    model = MockEmbeddingModel(dim=8) # Small dim for visibility\n",
    "    store = SimpleEmbeddingStore(model, namespace=\"entity\")\n",
    "\n",
    "    # Day 1: Indexing some entities\n",
    "    print(\"Step 1: First indexing...\")\n",
    "    entities_v1 = [\"Houston\", \"Texas\", \"University\"]\n",
    "    store.insert(entities_v1)\n",
    "\n",
    "    # Day 2: Indexing more entities (including some duplicates)\n",
    "    print(\"\\nStep 2: Second indexing (with duplicates)...\")\n",
    "    entities_v2 = [\"Houston\", \"USA\", \"NASA\"] # Houston is a duplicate\n",
    "    store.insert(entities_v2)\n",
    "\n",
    "    # Final Result\n",
    "    vectors = store.get_all_vectors()\n",
    "    print(f\"\\nFinal Store Size: {len(store.cache)} unique entities\")\n",
    "    print(f\"Matrix Shape for GNN: {vectors.shape}\")\n",
    "    \n",
    "    # How it links to the Graph:\n",
    "    sample_entity = \"Houston\"\n",
    "    h_id = store._compute_hash(sample_entity)\n",
    "    idx = store.hash_id_to_idx[h_id]\n",
    "    print(f\"The entity '{sample_entity}' is mapped to GNN Node Index: {idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3f0af197",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'1'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 100\u001b[39m\n\u001b[32m     97\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m data, e2e_relation_texts\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m     graph, relations = \u001b[43mtest_construction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m--- Graph with Edge Attributes ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    102\u001b[39m     \u001b[38;5;28mprint\u001b[39m(graph)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 77\u001b[39m, in \u001b[36mtest_construction\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m p_idx, ents \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(all_entities):\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m ent \u001b[38;5;129;01min\u001b[39;00m ents:\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m         e2p_edges.append([\u001b[43mentity_to_idx\u001b[49m\u001b[43m[\u001b[49m\u001b[43ment\u001b[49m\u001b[43m]\u001b[49m, p_idx])\n\u001b[32m     79\u001b[39m data[\u001b[33m'\u001b[39m\u001b[33mentity\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33min\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msentence\u001b[39m\u001b[33m'\u001b[39m].edge_index = torch.tensor(e2s_edges).t().contiguous()\n\u001b[32m     80\u001b[39m data[\u001b[33m'\u001b[39m\u001b[33msentence\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mhv\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mentity\u001b[39m\u001b[33m'\u001b[39m].edge_index = torch.tensor([[v, k] \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m e2s_edges]).t().contiguous()\n",
      "\u001b[31mKeyError\u001b[39m: '1'"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch_geometric.data import HeteroData\n",
    "import hashlib\n",
    "\n",
    "# --- SIMULATED DATA ---\n",
    "triples = [\n",
    "    (\"The Collegian\", \"is publication of\", \"Houston Baptist University\"),\n",
    "    (\"The Collegian\", \"founded in\", \"1963\")\n",
    "]\n",
    "passages=[\"The Collegian is the bi-weekly official student publication of Houston Baptist University in Houston, Texas.\",\n",
    "    \"It was founded in 1963 as a newsletter.\"]\n",
    "\n",
    "sentences = [\n",
    "    \"The Collegian is the bi-weekly official student publication of Houston Baptist University in Houston, Texas.\",\n",
    "    \"It was founded in 1963 as a newsletter.\"\n",
    "]\n",
    "\n",
    "sentence_entities = [\n",
    "    [\"The Collegian\", \"Houston Baptist University\", \"Houston\", \"Texas\"],\n",
    "    [\"1963\", \"newsletter\"]\n",
    "]\n",
    "structural_rel_emb = {\n",
    "    \"in\": torch.randn(1, 128),      # \"Contains\" relationship\n",
    "    \"hv\": torch.randn(1, 128),      # \"Held by\" relationship\n",
    "    \"seq\": torch.randn(1, 128)      # \"Sequential\" relationship\n",
    "}\n",
    "def test_construction():\n",
    "    data = HeteroData()\n",
    "    EMB_DIM = 128\n",
    "    \n",
    "    # Unique entities\n",
    "    all_entities = sorted(list(set([t[0] for t in triples] + [t[2] for t in triples] + [ent for sublist in sentence_entities for ent in sublist])))\n",
    "    entity_to_idx = {ent: i for i, ent in enumerate(all_entities)}\n",
    "    \n",
    "    # 1. Nodes\n",
    "    data['entity'].x = torch.randn(len(all_entities), EMB_DIM)\n",
    "    data['sentence'].x = torch.randn(len(sentences), EMB_DIM)\n",
    "    data['passage'].x = torch.randn(len(passages), EMB_DIM)\n",
    "\n",
    "    # 2. Edges with Attributes\n",
    "    # A. Entity -> Entity (from Triples)\n",
    "    e2e_edges = []\n",
    "    e2e_relation_texts = []\n",
    "    for sub, rel, obj in triples:\n",
    "        s_idx, o_idx = entity_to_idx[sub], entity_to_idx[obj]\n",
    "        \n",
    "        # A. FORWARD RELATION\n",
    "        e2e_edges.append([s_idx, o_idx])\n",
    "        e2e_relation_texts.append(rel)\n",
    "        \n",
    "        # B. INVERSE RELATION (The \"Reasoning\" Path)\n",
    "        e2e_edges.append([o_idx, s_idx])\n",
    "        e2e_relation_texts.append(f\"inverse {rel}\") # or use a mapping like 'is_part_of' -> 'contains'\n",
    "        \n",
    "\n",
    "        \n",
    "    data['entity', 're', 'entity'].edge_index = torch.tensor(e2e_edges).t().contiguous()\n",
    "    # In real code, your embedding model would encode these strings\n",
    "    # Forward and Inverse edges now have distinct embeddings!\n",
    "    data['entity', 're', 'entity'].edge_attr = torch.randn(len(e2e_relation_texts), EMB_DIM)\n",
    "\n",
    "    # B. Sentence -> Passage (Hierarchical)\n",
    "    s2p_edges = [[i, i] for i in range(len(sentences))]\n",
    "    data['sentence', 'in', 'passage'].edge_index = torch.tensor([[i, 0] for i in range(len(sentences))]).t().contiguous()\n",
    "    data['passage', 'hv', 'sentence'].edge_index = torch.tensor([[0, i] for i in range(len(sentences))]).t().contiguous()\n",
    "\n",
    "    data['sentence', 'in', 'passage'].edge_attr = structural_rel_emb[\"in\"].expand(len([[i, 0] for i in range(len(sentences))]), -1)\n",
    "    data['passage', 'hv', 'sentence'].edge_attr = structural_rel_emb[\"hv\"].expand(len([[0, i] for i in range(len(sentences))]), -1)\n",
    "\n",
    "    # C. Entity -> Sentence\n",
    "    e2s_edges = []\n",
    "    for s_idx, ents in enumerate(sentence_entities):\n",
    "        for ent in ents:\n",
    "            e2s_edges.append([entity_to_idx[ent], s_idx])\n",
    "    \n",
    "    e2p_edges = []\n",
    "    for ents in sentence_entities:\n",
    "        for ent in ents:\n",
    "            # We map the entity index to the passage index (which is 0 in this mock)\n",
    "            # Use a check to avoid duplicate edges if an entity appears in multiple sentences\n",
    "            edge = [entity_to_idx[ent], 0]\n",
    "            if edge not in e2p_edges:\n",
    "                e2p_edges.append(edge)\n",
    "\n",
    "    data['entity', 'in', 'sentence'].edge_index = torch.tensor(e2s_edges).t().contiguous()\n",
    "    data['sentence', 'hv', 'entity'].edge_index = torch.tensor([[v, k] for k, v in e2s_edges]).t().contiguous()\n",
    "\n",
    "    # FIX: Use len(e2s_edges) instead of the sentences list\n",
    "    data['entity', 'in', 'passage'].edge_attr = structural_rel_emb[\"in\"].expand(len(e2p_edges), -1)\n",
    "    data['passage', 'hv', 'entity'].edge_attr = structural_rel_emb[\"hv\"].expand(len(e2p_edges), -1)\n",
    "\n",
    "    # D. Sentence -> Sentence (Intra-passage flow)\n",
    "    s2s_edges = []\n",
    "    for i in range(len(sentences)):\n",
    "        for j in range(len(sentences)):\n",
    "            if i != j: s2s_edges.append([i, j])\n",
    "            \n",
    "    data['sentence', 're', 'sentence'].edge_index = torch.tensor(s2s_edges).t().contiguous()\n",
    "    \n",
    "    # FIX: Use len(s2s_edges) and assign after edge_index is created\n",
    "    data['sentence', 're', 'sentence'].edge_attr = structural_rel_emb[\"seq\"].expand(len(s2s_edges), -1)\n",
    "\n",
    "    return data, e2e_relation_texts\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    graph, relations = test_construction()\n",
    "    print(\"--- Graph with Edge Attributes ---\")\n",
    "    print(graph)\n",
    "    print(f\"Total Entity Edges: {graph['entity', 're', 'entity'].edge_index.shape[1]}\")\n",
    "    for i, rel in enumerate(relations):\n",
    "        src = graph['entity', 're', 'entity'].edge_index[0, i]\n",
    "        tgt = graph['entity', 're', 'entity'].edge_index[1, i]\n",
    "        print(f\"  Edge {i}: {rel} ({src.item()} -> {tgt.item()})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2f0e3097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Edge-Aware Message Passing Result (Algorithm 2) ---\n",
      "Updated Entities Shape: 3\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import softmax\n",
    "from torch_scatter import scatter_add\n",
    "from torch_geometric.nn import HeteroConv\n",
    "\n",
    "# --- EDGE-AWARE MESSAGE PASSING LAYER (Strict Algorithm 2) ---\n",
    "class EdgeAwareMessagePassing(nn.Module):\n",
    "    def __init__(self, h_dim):\n",
    "        super().__init__()\n",
    "        self.h_dim = h_dim\n",
    "        # MLP to compute attention score from [src, tgt, edge] only\n",
    "        # Changed from 4 * h_dim to 3 * h_dim\n",
    "        self.attn_mlp = nn.Linear(3 * h_dim, 1) \n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr=None):\n",
    "        if isinstance(x, tuple):\n",
    "            src_h, tgt_h = x\n",
    "        else:\n",
    "            src_h = tgt_h = x # for enoty-- entity relation\n",
    "        src, tgt = edge_index\n",
    "\n",
    "        h_i = src_h[src]      # Source node features (h_i)\n",
    "        h_j = tgt_h[tgt]      # Target node features (h_j)\n",
    "        e_ij = edge_attr      # Edge attributes (e_ij)\n",
    "        \n",
    "        # Line 7 of Algorithm 2: Score = Attention(hi, hj, eij)\n",
    "        # Query is no longer part of this local edge calculation\n",
    "        combined = torch.cat([h_i, h_j, e_ij], dim=-1)\n",
    "        score = self.attn_mlp(combined)\n",
    "        \n",
    "        # Line 9: Normalize attention weights across neighbors\n",
    "        alpha = softmax(score, tgt)\n",
    "        \n",
    "        # Line 10: Aggregate neighbor features using the learned alpha\n",
    "        out = scatter_add(alpha * h_i, tgt, dim=0, dim_size=tgt_h.size(0))\n",
    "        return out\n",
    "\n",
    "# Demonstration\n",
    "if __name__ == \"__main__\":\n",
    "    # ... (assuming graph construction is same as before) ...\n",
    "    h_dim = 128\n",
    "    #layer = EdgeAwareMessagePassing(h_dim)\n",
    "    \n",
    "    # Process entity-to-entity relations without needing a query_vec here\n",
    "    # updated_entities = layer(\n",
    "    #     src_h=graph['entity'].x,\n",
    "    #     tgt_h=graph['entity'].x,\n",
    "    #     edge_attr=graph['entity', 're', 'entity'].edge_attr,\n",
    "    #     edge_index=graph['entity', 're', 'entity'].edge_index\n",
    "    # )\n",
    "    # updated_sentences = layer(\n",
    "    #     src_h=graph['sentence'].x,\n",
    "    #     tgt_h=graph['sentence'].x,\n",
    "    #     edge_attr=graph['sentence', 're', 'sentence'].edge_attr,\n",
    "    #     edge_index=graph['sentence', 're', 'sentence'].edge_index\n",
    "    # )\n",
    "    conv = HeteroConv({\n",
    "        ('entity', 're', 'entity'): EdgeAwareMessagePassing(h_dim),\n",
    "        ('sentence', 're', 'sentence'): EdgeAwareMessagePassing(h_dim),\n",
    "        ('entity', 'in', 'sentence'): EdgeAwareMessagePassing(h_dim),\n",
    "        ('sentence', 'in', 'passage'): EdgeAwareMessagePassing(h_dim),\n",
    "        ('passage', 'hv', 'sentence'): EdgeAwareMessagePassing(h_dim),\n",
    "    }, aggr='sum')\n",
    "    out_dict = conv(\n",
    "        x_dict=graph.x_dict, \n",
    "        edge_index_dict=graph.edge_index_dict,\n",
    "        edge_attr_dict=graph.edge_attr_dict # Passes the right attr to the right layer!\n",
    "    )\n",
    "    print(\"\\n--- Edge-Aware Message Passing Result (Algorithm 2) ---\")\n",
    "    print(f\"Updated Entities Shape: {len(out_dict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93ebe91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd099ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuditableHybridGNN(torch.nn.Module):\n",
    "    def __init__(self, node_types, edge_types, hidden_dim):\n",
    "        # Local Track: Heterogeneous Graph Transformer (HGT)\n",
    "        # Captures: \"Sentence IN Passage\", \"Entity RE Entity\" (The Audit Path)\n",
    "        self.local_hgt = HGTConv(hidden_dim, hidden_dim, metadata)\n",
    "        \n",
    "        # Global Track: SGFormer-style All-to-All Attention\n",
    "        # Captures: Semantic connections across the whole KG (Pluralistic Oversight)\n",
    "        self.global_attn = MultiheadAttention(hidden_dim, heads=4)\n",
    "        \n",
    "        # Query-Gating Layer: Forces model to align with User Intent\n",
    "        self.query_gate = Linear(hidden_dim * 2, hidden_dim)\n",
    "\n",
    "    def forward(self, hetero_data, query_emb):\n",
    "        # 1. Structural Reasoning (Local Track)\n",
    "        # We extract attention weights here for the \"Audit Trail\" visualization\n",
    "        h_dict, local_attn_weights = self.local_hgt(hetero_data.x_dict, hetero_data.edge_index_dict)\n",
    "        \n",
    "        # 2. Semantic Cross-Referencing (Global Track)\n",
    "        # Convert to homogeneous to let every node talk to every other node\n",
    "        h_all = to_homogeneous(h_dict)\n",
    "        h_global = self.global_attn(h_all, h_all, h_all) \n",
    "        \n",
    "        # 3. Query Alignment (The QSGNN Secret Sauce)\n",
    "        # Scale every node's importance based on the query signal\n",
    "        aligned_h_dict = {}\n",
    "        for node_type, h in h_dict.items():\n",
    "            # Concatenate node feature with query vector\n",
    "            gate_input = torch.cat([h, query_emb.repeat(h.size(0), 1)], dim=-1)\n",
    "            importance_score = self.query_gate(gate_input).sigmoid()\n",
    "            # The node is updated by both local path and global verification\n",
    "            aligned_h_dict[node_type] = (h + h_global[node_type]) * importance_score\n",
    "            \n",
    "        # 4. Final Scoring (Retrieval Head)\n",
    "        # Output relevance scores for the Documents (D) or Chunks (C)\n",
    "        return self.scoring_head(aligned_h_dict['passage'], query_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43df7eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import HGTConv, Linear\n",
    "from torch_geometric.utils import to_homogeneous, from_homogeneous\n",
    "\n",
    "class AuditableHybridGNN(torch.nn.Module):\n",
    "    def __init__(self, metadata, hidden_dim, out_channels, num_heads=4):\n",
    "        super().__init__()\n",
    "        # 1. Local Track (Heterogeneous Graph Transformer)\n",
    "        # metadata contains (node_types, edge_types)\n",
    "        self.local_hgt = HGTConv(hidden_dim, hidden_dim, metadata, num_heads)\n",
    "        \n",
    "        # 2. Global Track (SGFormer style)\n",
    "        self.global_attn = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=num_heads, batch_first=True)\n",
    "        \n",
    "        # 3. Query Alignment Gate\n",
    "        # We take node features + query features\n",
    "        self.query_gate = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # 4. Final Scoring Head (The Learned Scoring Head from Algorithm 4)\n",
    "        self.scoring_head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, query_emb):\n",
    "        # --- PHASE 1: Structural Reasoning (Local) ---\n",
    "        # HGT processes nodes based on their specific relationships\n",
    "        h_dict = self.local_hgt(x_dict, edge_index_dict)\n",
    "        \n",
    "        # --- PHASE 2: Semantic Oversight (Global) ---\n",
    "        # 1. Collapse to homogeneous to allow all-to-all attention\n",
    "        # 'edge_index' is ignored here because we want a full attention matrix\n",
    "        h_homo, _ = self.collapse_to_homogeneous(h_dict) \n",
    "        \n",
    "        # 2. Global Self-Attention (every node looks at every other node)\n",
    "        # h_homo: [num_total_nodes, hidden_dim] -> add batch dim for MHA\n",
    "        h_global, _ = self.global_attn(query_emb, h_homo.unsqueeze(0), h_homo.unsqueeze(0))\n",
    "        h_global = h_global.squeeze(0)\n",
    "        \n",
    "        # --- PHASE 3: Query Gating & Fusion ---\n",
    "        out_dict = {}\n",
    "        for node_type, h_local in h_dict.items():\n",
    "            # Fuse local and global knowledge\n",
    "            # (In reality, we map the global embeddings back to their node types)\n",
    "            h_fused = h_local + self.extract_global_for_type(h_global, node_type)\n",
    "            \n",
    "            # Query Alignment: Scale node importance based on query\n",
    "            # Repeat query_emb to match number of nodes of this type\n",
    "            q_expanded = query_emb.expand(h_fused.size(0), -1)\n",
    "            gate_input = torch.cat([h_fused, q_expanded], dim=-1)\n",
    "            importance = self.query_gate(gate_input)\n",
    "            \n",
    "            out_dict[node_type] = h_fused * importance\n",
    "\n",
    "        # --- PHASE 4: Final Retrieval Scoring ---\n",
    "        # Scoring based on Passage nodes as in RAG\n",
    "        passage_embeddings = out_dict['passage']\n",
    "        q_for_scoring = query_emb.expand(passage_embeddings.size(0), -1)\n",
    "        scores = self.scoring_head(torch.cat([passage_embeddings, q_for_scoring], dim=-1))\n",
    "        \n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c58d3b4b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Found indices in 'edge_index' that are larger than 8 (got 9). Please ensure that all indices in 'edge_index' point to valid indices in the interval [0, 9) in your node feature matrix and try again.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/gnn-hgt-4314cFo1-py3.12/lib/python3.12/site-packages/torch_geometric/nn/conv/message_passing.py:271\u001b[39m, in \u001b[36mMessagePassing._index_select_safe\u001b[39m\u001b[34m(self, src, index)\u001b[39m\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m271\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msrc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex_select\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnode_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mIndexError\u001b[39m: index out of range in self",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 136\u001b[39m\n\u001b[32m    134\u001b[39m \u001b[38;5;66;03m# Training Loop\u001b[39;00m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m10\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m     loss = \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmock_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgold_passage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m     correct = test_step(model, graph, mock_query, gold_passage)\n\u001b[32m    138\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | Correct: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcorrect\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 100\u001b[39m, in \u001b[36mtrain_step\u001b[39m\u001b[34m(model, data, query_emb, target_passage_idx, optimizer, criterion)\u001b[39m\n\u001b[32m     96\u001b[39m optimizer.zero_grad() \u001b[38;5;66;03m# Clear previous gradients\u001b[39;00m\n\u001b[32m     98\u001b[39m \u001b[38;5;66;03m# 1. Forward Pass\u001b[39;00m\n\u001b[32m     99\u001b[39m \u001b[38;5;66;03m# We pass the graph data and the query we are looking for\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m predicted_scores = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mx_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43medge_index_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_emb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[38;5;66;03m# 2. Calculate Loss\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[38;5;66;03m# We want the 'target_passage_idx' to have the highest score\u001b[39;00m\n\u001b[32m    104\u001b[39m \u001b[38;5;66;03m# CrossEntropy expects (all_scores, index_of_the_right_one)\u001b[39;00m\n\u001b[32m    105\u001b[39m loss = criterion(predicted_scores.unsqueeze(\u001b[32m0\u001b[39m), torch.tensor([target_passage_idx]).to(predicted_scores.device))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/gnn-hgt-4314cFo1-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/gnn-hgt-4314cFo1-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mAuditableHybridGNN.forward\u001b[39m\u001b[34m(self, x_dict, edge_index_dict, query_emb)\u001b[39m\n\u001b[32m     36\u001b[39m     query_emb = query_emb.unsqueeze(\u001b[32m0\u001b[39m)\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# 1. Local Track (HGT)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m h_dict = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlocal_hgt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# 2. Global Entity Reasoning\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# query_emb: [1, 1, dim]\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# entities: [Num_Entities, dim]\u001b[39;00m\n\u001b[32m     43\u001b[39m entities = h_dict[\u001b[33m'\u001b[39m\u001b[33mentity\u001b[39m\u001b[33m'\u001b[39m].unsqueeze(\u001b[32m0\u001b[39m) \u001b[38;5;66;03m# [1, Num_Entities, dim]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/gnn-hgt-4314cFo1-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/gnn-hgt-4314cFo1-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/gnn-hgt-4314cFo1-py3.12/lib/python3.12/site-packages/torch_geometric/nn/conv/hgt_conv.py:199\u001b[39m, in \u001b[36mHGTConv.forward\u001b[39m\u001b[34m(self, x_dict, edge_index_dict)\u001b[39m\n\u001b[32m    192\u001b[39m k, v, src_offset = \u001b[38;5;28mself\u001b[39m._construct_src_node_feat(\n\u001b[32m    193\u001b[39m     k_dict, v_dict, edge_index_dict)\n\u001b[32m    195\u001b[39m edge_index, edge_attr = construct_bipartite_edge_index(\n\u001b[32m    196\u001b[39m     edge_index_dict, src_offset, dst_offset, edge_attr_dict=\u001b[38;5;28mself\u001b[39m.p_rel,\n\u001b[32m    197\u001b[39m     num_nodes=k.size(\u001b[32m0\u001b[39m))\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m=\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m=\u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[38;5;66;03m# Reconstruct output node embeddings dict:\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m node_type, start_offset \u001b[38;5;129;01min\u001b[39;00m dst_offset.items():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/var/folders/fr/gfqqb60s0ldfjkfv6636pfvc0000gn/T/torch_geometric.nn.conv.hgt_conv_HGTConv_propagate_8ckj0amf.py:203\u001b[39m, in \u001b[36mpropagate\u001b[39m\u001b[34m(self, edge_index, k, q, v, edge_attr, size)\u001b[39m\n\u001b[32m    199\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mmessage_and_aggregate\u001b[39m\u001b[33m'\u001b[39m\u001b[33m not implemented\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     kwargs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m        \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m        \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m        \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmutable_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    212\u001b[39m     \u001b[38;5;66;03m# Begin Message Forward Pre Hook #######################################\u001b[39;00m\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.jit.is_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/var/folders/fr/gfqqb60s0ldfjkfv6636pfvc0000gn/T/torch_geometric.nn.conv.hgt_conv_HGTConv_propagate_8ckj0amf.py:120\u001b[39m, in \u001b[36mcollect\u001b[39m\u001b[34m(self, edge_index, k, q, v, edge_attr, size)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(q, Tensor):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28mself\u001b[39m._set_size(size, i, q)\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m     q_i = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_index_select\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index_i\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    122\u001b[39m     q_i = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/gnn-hgt-4314cFo1-py3.12/lib/python3.12/site-packages/torch_geometric/nn/conv/message_passing.py:267\u001b[39m, in \u001b[36mMessagePassing._index_select\u001b[39m\u001b[34m(self, src, index)\u001b[39m\n\u001b[32m    265\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m src.index_select(\u001b[38;5;28mself\u001b[39m.node_dim, index)\n\u001b[32m    266\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_index_select_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/gnn-hgt-4314cFo1-py3.12/lib/python3.12/site-packages/torch_geometric/nn/conv/message_passing.py:282\u001b[39m, in \u001b[36mMessagePassing._index_select_safe\u001b[39m\u001b[34m(self, src, index)\u001b[39m\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[32m    275\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound negative indices in \u001b[39m\u001b[33m'\u001b[39m\u001b[33medge_index\u001b[39m\u001b[33m'\u001b[39m\u001b[33m (got \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    276\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex.min().item()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m). Please ensure that all \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    277\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mindices in \u001b[39m\u001b[33m'\u001b[39m\u001b[33medge_index\u001b[39m\u001b[33m'\u001b[39m\u001b[33m point to valid indices \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    278\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33min the interval [0, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc.size(\u001b[38;5;28mself\u001b[39m.node_dim)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) in \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    279\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33myour node feature matrix and try again.\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (index.numel() > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m index.max() >= src.size(\u001b[38;5;28mself\u001b[39m.node_dim)):\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[32m    283\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound indices in \u001b[39m\u001b[33m'\u001b[39m\u001b[33medge_index\u001b[39m\u001b[33m'\u001b[39m\u001b[33m that are larger \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    284\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mthan \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc.size(\u001b[38;5;28mself\u001b[39m.node_dim)\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (got \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex.max().item()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m). Please ensure that all \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mindices in \u001b[39m\u001b[33m'\u001b[39m\u001b[33medge_index\u001b[39m\u001b[33m'\u001b[39m\u001b[33m point to valid indices \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    287\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33min the interval [0, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc.size(\u001b[38;5;28mself\u001b[39m.node_dim)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) in \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    288\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33myour node feature matrix and try again.\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    290\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[31mIndexError\u001b[39m: Found indices in 'edge_index' that are larger than 8 (got 9). Please ensure that all indices in 'edge_index' point to valid indices in the interval [0, 9) in your node feature matrix and try again."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import HGTConv\n",
    "#from torch_geometric.utils import to_homogeneous\n",
    "\n",
    "# --- 1. THE HYBRID MODEL ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import HGTConv\n",
    "from torch_geometric.utils import scatter\n",
    "\n",
    "\n",
    "class AuditableHybridGNN(nn.Module):\n",
    "    def __init__(self, metadata, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.local_hgt = HGTConv(hidden_dim, hidden_dim, metadata, heads=4)\n",
    "        \n",
    "        # Cross-Attention: Query attends to Entities ONLY\n",
    "        self.entity_global_attn = nn.MultiheadAttention(hidden_dim, num_heads=4, batch_first=True)\n",
    "        # --- NEW: STABILITY LAYERS ---\n",
    "        # LayerNormy ensures that adding two vectors doesn't make the values \"explode\"\n",
    "        self.entity_norm = nn.LayerNorm(hidden_dim)\n",
    "        self.passage_norm = nn.LayerNorm(hidden_dim)\n",
    "        self.alpha = 0.1\n",
    "        # Scoring Head\n",
    "        # SCORING HEAD\n",
    "        self.scoring_head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, query_emb):\n",
    "        if query_emb.dim() == 1:\n",
    "            query_emb = query_emb.unsqueeze(0)\n",
    "        # 1. Local Track (HGT)\n",
    "        h_dict = self.local_hgt(x_dict, edge_index_dict)\n",
    "        \n",
    "        # 2. Global Entity Reasoning\n",
    "        # query_emb: [1, 1, dim]\n",
    "        # entities: [Num_Entities, dim]\n",
    "        entities = h_dict['entity'].unsqueeze(0) # [1, Num_Entities, dim]\n",
    "        query = query_emb.unsqueeze(0)           # [1, 1, dim]\n",
    "        \n",
    "        # Query acts as the 'Key' and 'Value', Entities are the 'Query'\n",
    "        # Or vice-versa: Let Entities attend to each other globally\n",
    "        h_local = h_dict['entity'] \n",
    "        h_ent_global, _ = self.entity_global_attn(entities, entities, entities)\n",
    "        #overrighting - means catestraophic forgetting\n",
    "        #h_dict['entity'] = h_ent_global.squeeze(0)\n",
    "        # 3. ADD them instead of OVERWRITING (Residual Connection)\n",
    "        # This ensures the model keeps BOTH structural and semantic info.\n",
    "        #h_dict['entity'] = h_local + h_ent_global\n",
    "        h_dict['entity'] = self.entity_norm((1 - self.alpha) * h_local + self.alpha * h_ent_global) # weighted fushion and normalization\n",
    "        \n",
    "        # 3. The \"Broadcast\" Step\n",
    "        # Now, update Passages using the NEW Entity info\n",
    "        # We can use the 'entity_in_passage' edges to pull info\n",
    "        # or a simple mean-pooling of entities per passage\n",
    "        # 3. The \"Broadcast\" Step (Query-Guided)\n",
    "        e2p_index = edge_index_dict[('entity', 'in', 'passage')]\n",
    "        ent_idx, psg_idx = e2p_index\n",
    "\n",
    "        # Step A: Calculate which entities match the query (Relevance Score)\n",
    "        # Shape: [Num_Entities]\n",
    "        q_expanded = query_emb.expand(h_dict['entity'].size(0), -1)\n",
    "        relevance = torch.sum(h_dict['entity'] * q_expanded, dim=-1).sigmoid()\n",
    "\n",
    "        # Step B: Weight the entity features before sending them to the passage\n",
    "        # This effectively \"mutes\" irrelevant entities in the document\n",
    "        weighted_ent_features = h_dict['entity'][ent_idx] * relevance[ent_idx].unsqueeze(-1)\n",
    "\n",
    "        # Step C: Aggregate (Sum) to get the \"Query-Relevant Document Context\"\n",
    "        psg_context = scatter(src=weighted_ent_features, \n",
    "                            index=psg_idx, \n",
    "                            dim=0, \n",
    "                            dim_size=h_dict['passage'].size(0), \n",
    "                            reduce='sum')\n",
    "\n",
    "        # Step D: Update\n",
    "        h_dict['passage'] = self.passage_norm(h_dict['passage'] + psg_context)\n",
    "\n",
    "\n",
    "        # 4. Final Scoring\n",
    "        passages = h_dict['passage']\n",
    "        q_scoring = query_emb.expand(passages.size(0), -1)\n",
    "        \n",
    "        # Combine Passage info + Query info\n",
    "        return self.scoring_head(torch.cat([passages, q_scoring], dim=-1)).squeeze()\n",
    "\n",
    "\n",
    "# --- 2. THE TRAINING & EVALUATION LOGIC ---\n",
    "def train_step(model, data, query_emb, target_passage_idx, optimizer, criterion):\n",
    "    model.train() # Set to training mode (enables dropout, etc.)\n",
    "    optimizer.zero_grad() # Clear previous gradients\n",
    "    \n",
    "    # 1. Forward Pass\n",
    "    # We pass the graph data and the query we are looking for\n",
    "    predicted_scores = model(data.x_dict, data.edge_index_dict, query_emb)\n",
    "    \n",
    "    # 2. Calculate Loss\n",
    "    # We want the 'target_passage_idx' to have the highest score\n",
    "    # CrossEntropy expects (all_scores, index_of_the_right_one)\n",
    "    loss = criterion(predicted_scores.unsqueeze(0), torch.tensor([target_passage_idx]).to(predicted_scores.device))\n",
    "    \n",
    "    # 3. Backward Pass (The \"Update\" phase)\n",
    "    loss.backward() # Calculate gradients\n",
    "    optimizer.step() # Update weights based on gradients\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "def test_step(model, data, query_emb, target_passage_idx):\n",
    "    model.eval() # Set to evaluation mode (disables dropout)\n",
    "    with torch.no_grad(): # Don't calculate gradients (saves memory/time)\n",
    "        scores = model(data.x_dict, data.edge_index_dict, query_emb)\n",
    "        # Find which passage got the highest score\n",
    "        pred_idx = torch.argmax(scores).item()\n",
    "        is_correct = (pred_idx == target_passage_idx)\n",
    "    return is_correct\n",
    "\n",
    "# --- 3. EXECUTION ---\n",
    "# Setup\n",
    "hidden_dim = 128\n",
    "# Assuming 'graph' is your HeteroData object from previous steps\n",
    "model = AuditableHybridGNN(graph.metadata(), hidden_dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Mock training data (1 query, looking for passage index 5)\n",
    "mock_query = torch.randn(1, hidden_dim)\n",
    "gold_passage = 5\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(10):\n",
    "    loss = train_step(model, graph, mock_query, gold_passage, optimizer, criterion)\n",
    "    correct = test_step(model, graph, mock_query, gold_passage)\n",
    "    print(f\"Epoch {epoch} | Loss: {loss:.4f} | Correct: {correct}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4b4b15",
   "metadata": {},
   "source": [
    "## lets construct the knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e9767c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "dataset_name = \"musique\"\n",
    "\n",
    "corpus_path = f\"dataset/{dataset_name}_corpus.json\"\n",
    "with open(corpus_path, \"r\") as f:\n",
    "    corpus = json.load(f)\n",
    "\n",
    "docs = [f\"{doc['title']}\\n{doc['text']}\" for doc in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "754a6ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Catalan language\\nThe Germanic superstrate has had different outcomes in Spanish and Catalan. For example, Catalan fang \"mud\" and rostir \"to roast\", of Germanic origin, contrast with Spanish lodo and asar, of Latin origin; whereas Catalan filosa \"spinning wheel\" and pols \"temple\", of Latin origin, contrast with Spanish rueca and sien, of Germanic origin.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377ad7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.chunk_embedding_store.insert_strings(docs)\n",
    "chunk_to_rows = self.chunk_embedding_store.get_all_id_to_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22e8a008",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hashlib import md5\n",
    "\n",
    "def compute_mdhash_id(content: str, prefix: str = \"\") -> str:\n",
    "    return prefix + md5(content.encode()).hexdigest()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8acdb4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "texts = []\n",
    "hash_ids = []\n",
    "def _upsert(hash_ids, texts, embeddings):\n",
    "    embeddings.extend(embeddings)\n",
    "    hash_ids.extend(hash_ids)\n",
    "    texts.extend(texts)\n",
    "\n",
    "    #logger.info(f\"Saving new records.\")\n",
    "    #self._save_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "622fa92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanzeel.shaikh/Library/Caches/pypoetry/virtualenvs/gnn-hgt-4314cFo1-py3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModel\n",
    "from typing import List, Optional\n",
    "\n",
    "class NVEmbedV2EmbeddingModel:\n",
    "    def __init__(self, model_name: str = \"nvidia/NV-Embed-v2\"):\n",
    "        \"\"\"\n",
    "        Initializes the NV-Embed-v2 model.\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        \n",
    "        # Load the model with trust_remote_code=True for NV-Embed\n",
    "        self.model = AutoModel.from_pretrained(\n",
    "            model_name,\n",
    "            trust_remote_code=True,\n",
    "            torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n",
    "            device_map=\"auto\" if torch.cuda.is_available() else None\n",
    "        )\n",
    "        \n",
    "    def batch_encode(\n",
    "        self, \n",
    "        texts: List[str], \n",
    "        batch_size: int = 16, \n",
    "        max_length: int = 32768, \n",
    "        instruction: str = \"\", \n",
    "        norm: bool = True\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Encodes a list of strings into embeddings.\n",
    "        \"\"\"\n",
    "        if isinstance(texts, str):\n",
    "            texts = [texts]\n",
    "\n",
    "        # Prepare instructions according to NV-Embed format\n",
    "        formatted_instruction = f\"Instruct: {instruction}\\nQuery: \" if instruction else \"\"\n",
    "\n",
    "        results = []\n",
    "        if len(texts) <= batch_size:\n",
    "            # Single batch\n",
    "            results = self.model.encode(\n",
    "                prompts=texts, \n",
    "                instruction=formatted_instruction, \n",
    "                max_length=max_length\n",
    "            )\n",
    "        else:\n",
    "            # Multiple batches with progress bar\n",
    "            for i in tqdm(range(0, len(texts), batch_size), desc=\"Batch Encoding\"):\n",
    "                batch_texts = texts[i : i + batch_size]\n",
    "                batch_results = self.model.encode(\n",
    "                    prompts=batch_texts, \n",
    "                    instruction=formatted_instruction, \n",
    "                    max_length=max_length\n",
    "                )\n",
    "                results.append(batch_results)\n",
    "            results = torch.cat(results, dim=0)\n",
    "\n",
    "        # Convert to numpy\n",
    "        if isinstance(results, torch.Tensor):\n",
    "            results = results.cpu().float().numpy()\n",
    "            \n",
    "        # L2 Normalization\n",
    "        if norm:\n",
    "            results = (results.T / np.linalg.norm(results, axis=1)).T\n",
    "\n",
    "        return results\n",
    "\n",
    "# --- Usage ---\n",
    "# 1. Initialize the model (only needs to be done once)\n",
    "# model_instance = NVEmbedV2EmbeddingModel()\n",
    "\n",
    "# 2. Encode your texts\n",
    "# missing_embeddings = model_instance.batch_encode(texts_to_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ef323c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting 0 new records, 15803 records already exist.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards:  25%|██▌       | 1/4 [00:08<00:26,  8.94s/it]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\"\n",
    "\n",
    "nodes_dict = {}\n",
    "hashes=[]\n",
    "content=[]\n",
    "for text in docs:\n",
    "    hash_id = compute_mdhash_id(text, prefix='docs' + \"-\")\n",
    "    nodes_dict[hash_id] = {'content': text}\n",
    "    hashes.append(hash_id)\n",
    "    content.append(text)\n",
    "\n",
    "hash_id_to_row = {\n",
    "                h: {\"hash_id\": h, \"content\": t}\n",
    "                for h, t in zip(hashes,content)\n",
    "            }\n",
    "\n",
    "# Get all hash_ids from the input dictionary.\n",
    "all_hash_ids = list(nodes_dict.keys())\n",
    "#if not all_hash_ids:\n",
    "#    return  # Nothing to insert.\n",
    "\n",
    "existing = hash_id_to_row.keys()\n",
    "\n",
    "# Filter out the missing hash_ids.\n",
    "missing_ids = [hash_id for hash_id in all_hash_ids if hash_id not in existing]\n",
    "\n",
    "print(f\"Inserting {len(missing_ids)} new records, {len(all_hash_ids) - len(missing_ids)} records already exist.\")\n",
    "\n",
    "#if not missing_ids:\n",
    "#    return  {}# All records already exist.\n",
    "\n",
    "# Prepare the texts to encode from the \"content\" field.\n",
    "texts_to_encode = [nodes_dict[hash_id][\"content\"] for hash_id in missing_ids]\n",
    "\n",
    "\n",
    "# --- Usage ---\n",
    "# 1. Initialize the model (only needs to be done once)\n",
    "model_instance = NVEmbedV2EmbeddingModel()\n",
    "\n",
    "# 2. Encode your texts\n",
    "missing_embeddings = model_instance.batch_encode(texts_to_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5352a1b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn-hgt-4314cFo1-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
